{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "titanic-notebook.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2021-10-15T16:43:08.424138Z",
          "iopub.execute_input": "2021-10-15T16:43:08.424876Z",
          "iopub.status.idle": "2021-10-15T16:43:08.436937Z",
          "shell.execute_reply.started": "2021-10-15T16:43:08.424826Z",
          "shell.execute_reply": "2021-10-15T16:43:08.435914Z"
        },
        "trusted": true,
        "id": "oQf9iC6u-NmN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb24a776-db53-4299-9aab-4422ed6a412a"
      },
      "source": [
        "!pip install --upgrade scikit-learn\n",
        "# 0.22.2.post1 -> 1.0\n",
        "# import sklearn\n",
        "# print(sklearn.__version__)\n",
        "\n",
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "## for Kaggle notebook\n",
        "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "#     for filename in filenames:\n",
        "#         print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (0.22.2.post1)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.0.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.2 MB 58.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-3.0.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n",
            "Installing collected packages: threadpoolctl, scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "Successfully installed scikit-learn-1.0.1 threadpoolctl-3.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "execution": {
          "iopub.status.busy": "2021-10-15T16:43:08.438866Z",
          "iopub.execute_input": "2021-10-15T16:43:08.439388Z",
          "iopub.status.idle": "2021-10-15T16:43:10.035303Z",
          "shell.execute_reply.started": "2021-10-15T16:43:08.439355Z",
          "shell.execute_reply": "2021-10-15T16:43:10.034059Z"
        },
        "trusted": true,
        "id": "nxaesgTI-NmR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16e67568-6a47-49fa-fc66-e7d83f340cf0"
      },
      "source": [
        "!pwd\n",
        "## Kaggle\n",
        "# !ls ../input\n",
        "\n",
        "## Colab\n",
        "# !wget 'https://wenzhan1o-my.sharepoint.com/:u:/g/personal/ievtt_kze_me/EagIcOFamPlHgERo56QclZYB20V0UhmNJTVXRpXk_bXqTQ?e=veLGfV&download=1' -O titanic.zip\n",
        "!wget 'https://bit.ly/3aODbKl' -O titanic.zip\n",
        "!unzip titanic.zip\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "--2021-11-03 10:53:23--  https://bit.ly/3aODbKl\n",
            "Resolving bit.ly (bit.ly)... 67.199.248.10, 67.199.248.11\n",
            "Connecting to bit.ly (bit.ly)|67.199.248.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://wenzhan1o-my.sharepoint.com/:u:/g/personal/ievtt_kze_me/EagIcOFamPlHgERo56QclZYB20V0UhmNJTVXRpXk_bXqTQ?e=veLGfV&download=1 [following]\n",
            "--2021-11-03 10:53:23--  https://wenzhan1o-my.sharepoint.com/:u:/g/personal/ievtt_kze_me/EagIcOFamPlHgERo56QclZYB20V0UhmNJTVXRpXk_bXqTQ?e=veLGfV&download=1\n",
            "Resolving wenzhan1o-my.sharepoint.com (wenzhan1o-my.sharepoint.com)... 13.107.136.9, 13.107.138.9\n",
            "Connecting to wenzhan1o-my.sharepoint.com (wenzhan1o-my.sharepoint.com)|13.107.136.9|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /personal/ievtt_kze_me/Documents/Study/Kaggle/Titanic/titanic.zip [following]\n",
            "--2021-11-03 10:53:23--  https://wenzhan1o-my.sharepoint.com/personal/ievtt_kze_me/Documents/Study/Kaggle/Titanic/titanic.zip\n",
            "Reusing existing connection to wenzhan1o-my.sharepoint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 34877 (34K) [application/x-zip-compressed]\n",
            "Saving to: ‘titanic.zip’\n",
            "\n",
            "titanic.zip         100%[===================>]  34.06K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2021-11-03 10:53:24 (2.52 MB/s) - ‘titanic.zip’ saved [34877/34877]\n",
            "\n",
            "Archive:  titanic.zip\n",
            "  inflating: gender_submission.csv   \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-15T16:43:10.037252Z",
          "iopub.execute_input": "2021-10-15T16:43:10.037736Z",
          "iopub.status.idle": "2021-10-15T16:43:10.111372Z",
          "shell.execute_reply.started": "2021-10-15T16:43:10.037686Z",
          "shell.execute_reply": "2021-10-15T16:43:10.109929Z"
        },
        "trusted": true,
        "id": "dTwWUwuo-NmS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df56a237-fed2-4bfd-e842-82bfbca8c744"
      },
      "source": [
        "## Kaggle Notebook\n",
        "# data_path = '../input/titanic/'\n",
        "## Colab\n",
        "data_path = './'\n",
        "\n",
        "train = pd.read_csv(data_path + 'train.csv')\n",
        "test = pd.read_csv(data_path + 'test.csv')\n",
        "gender_sub = pd.read_csv(data_path + 'gender_submission.csv')\n",
        "\n",
        "print(train.head(3))\n",
        "print(train.info())\n",
        "print(test.head(3))\n",
        "print(test.info())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
            "0            1         0       3  ...   7.2500   NaN         S\n",
            "1            2         1       1  ...  71.2833   C85         C\n",
            "2            3         1       3  ...   7.9250   NaN         S\n",
            "\n",
            "[3 rows x 12 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n",
            "None\n",
            "   PassengerId  Pclass                              Name  ...    Fare  Cabin  Embarked\n",
            "0          892       3                  Kelly, Mr. James  ...  7.8292    NaN         Q\n",
            "1          893       3  Wilkes, Mrs. James (Ellen Needs)  ...  7.0000    NaN         S\n",
            "2          894       2         Myles, Mr. Thomas Francis  ...  9.6875    NaN         Q\n",
            "\n",
            "[3 rows x 11 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 418 entries, 0 to 417\n",
            "Data columns (total 11 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  418 non-null    int64  \n",
            " 1   Pclass       418 non-null    int64  \n",
            " 2   Name         418 non-null    object \n",
            " 3   Sex          418 non-null    object \n",
            " 4   Age          332 non-null    float64\n",
            " 5   SibSp        418 non-null    int64  \n",
            " 6   Parch        418 non-null    int64  \n",
            " 7   Ticket       418 non-null    object \n",
            " 8   Fare         417 non-null    float64\n",
            " 9   Cabin        91 non-null     object \n",
            " 10  Embarked     418 non-null    object \n",
            "dtypes: float64(2), int64(4), object(5)\n",
            "memory usage: 36.0+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-15T16:43:10.113409Z",
          "iopub.execute_input": "2021-10-15T16:43:10.113985Z",
          "iopub.status.idle": "2021-10-15T16:43:10.160045Z",
          "shell.execute_reply.started": "2021-10-15T16:43:10.113951Z",
          "shell.execute_reply": "2021-10-15T16:43:10.159241Z"
        },
        "trusted": true,
        "id": "JR_HlY-8-NmS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39c77579-c30d-442f-f066-4a5987c97a40"
      },
      "source": [
        "# 統計量情報\n",
        "print(train.describe())\n",
        "print(test.describe())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       PassengerId    Survived      Pclass  ...       SibSp       Parch        Fare\n",
            "count   891.000000  891.000000  891.000000  ...  891.000000  891.000000  891.000000\n",
            "mean    446.000000    0.383838    2.308642  ...    0.523008    0.381594   32.204208\n",
            "std     257.353842    0.486592    0.836071  ...    1.102743    0.806057   49.693429\n",
            "min       1.000000    0.000000    1.000000  ...    0.000000    0.000000    0.000000\n",
            "25%     223.500000    0.000000    2.000000  ...    0.000000    0.000000    7.910400\n",
            "50%     446.000000    0.000000    3.000000  ...    0.000000    0.000000   14.454200\n",
            "75%     668.500000    1.000000    3.000000  ...    1.000000    0.000000   31.000000\n",
            "max     891.000000    1.000000    3.000000  ...    8.000000    6.000000  512.329200\n",
            "\n",
            "[8 rows x 7 columns]\n",
            "       PassengerId      Pclass         Age       SibSp       Parch        Fare\n",
            "count   418.000000  418.000000  332.000000  418.000000  418.000000  417.000000\n",
            "mean   1100.500000    2.265550   30.272590    0.447368    0.392344   35.627188\n",
            "std     120.810458    0.841838   14.181209    0.896760    0.981429   55.907576\n",
            "min     892.000000    1.000000    0.170000    0.000000    0.000000    0.000000\n",
            "25%     996.250000    1.000000   21.000000    0.000000    0.000000    7.895800\n",
            "50%    1100.500000    3.000000   27.000000    0.000000    0.000000   14.454200\n",
            "75%    1204.750000    3.000000   39.000000    1.000000    0.000000   31.500000\n",
            "max    1309.000000    3.000000   76.000000    8.000000    9.000000  512.329200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-15T16:43:10.162275Z",
          "iopub.execute_input": "2021-10-15T16:43:10.16283Z",
          "iopub.status.idle": "2021-10-15T16:43:10.202607Z",
          "shell.execute_reply.started": "2021-10-15T16:43:10.162794Z",
          "shell.execute_reply": "2021-10-15T16:43:10.201422Z"
        },
        "trusted": true,
        "id": "ova8cVzb-NmT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7185c282-4a64-4460-d4d9-db5d814c93d0"
      },
      "source": [
        "# 欠損データ\n",
        "def kesson_table(df):\n",
        "    nul_val = df.isnull().sum()\n",
        "    kesson_table = pd.concat([nul_val,100 * nul_val / len(df)],axis=1)\n",
        "    return(kesson_table.rename(columns={0:'欠損数',1:'%'}))\n",
        "\n",
        "print(kesson_table(train))\n",
        "print(kesson_table(test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             欠損数          %\n",
            "PassengerId    0   0.000000\n",
            "Survived       0   0.000000\n",
            "Pclass         0   0.000000\n",
            "Name           0   0.000000\n",
            "Sex            0   0.000000\n",
            "Age          177  19.865320\n",
            "SibSp          0   0.000000\n",
            "Parch          0   0.000000\n",
            "Ticket         0   0.000000\n",
            "Fare           0   0.000000\n",
            "Cabin        687  77.104377\n",
            "Embarked       2   0.224467\n",
            "             欠損数          %\n",
            "PassengerId    0   0.000000\n",
            "Pclass         0   0.000000\n",
            "Name           0   0.000000\n",
            "Sex            0   0.000000\n",
            "Age           86  20.574163\n",
            "SibSp          0   0.000000\n",
            "Parch          0   0.000000\n",
            "Ticket         0   0.000000\n",
            "Fare           1   0.239234\n",
            "Cabin        327  78.229665\n",
            "Embarked       0   0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87sjP7JG-NmU"
      },
      "source": [
        "* PassengerId – 乗客識別ユニークID\n",
        "* Survived – 生存フラグ（0=死亡、1=生存）\n",
        "* Pclass – チケットクラス\n",
        "    * 1 = 上層クラス（お金持ち）\n",
        "    * 2 = 中級クラス（一般階級）\n",
        "    * 3 = 下層クラス（労働階級）\n",
        "* Name – 乗客の名前\n",
        "* Sex – 性別（male=男性、female＝女性）\n",
        "* Age – 年齢\n",
        "* SibSp – タイタニックに同乗している兄弟/配偶者の数\n",
        "* parch – タイタニックに同乗している親/子供の数\n",
        "* Ticket – チケット番号\n",
        "* fare – 料金\n",
        "* cabin – 客室番号\n",
        "* Embarked – 出港地（タイタニックへ乗った港）\n",
        "    * C = Cherbourg\n",
        "    * Q = Queenstown\n",
        "    * S = Southampton\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AH23YnN4-NmV"
      },
      "source": [
        "## データセットの事前処理\n",
        "\n",
        "* 欠損データの補完\n",
        "    * Age：中央値\n",
        "    * Embarked：最頻値\n",
        "* 文字データ → カテゴリカルデータ\n",
        "\n",
        "【Kaggle初心者入門編】タイタニック号で生き残るのは誰？\n",
        "https://www.codexa.net/kaggle-titanic-beginner/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-15T16:43:10.204524Z",
          "iopub.execute_input": "2021-10-15T16:43:10.20518Z",
          "iopub.status.idle": "2021-10-15T16:43:10.267393Z",
          "shell.execute_reply.started": "2021-10-15T16:43:10.205129Z",
          "shell.execute_reply": "2021-10-15T16:43:10.266171Z"
        },
        "trusted": true,
        "id": "5yomnrph-NmW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15375ff8-6196-4897-920f-cc2db247dc20"
      },
      "source": [
        "import statistics\n",
        "\n",
        "embarked_na_fill = statistics.mode(train['Embarked'])\n",
        "\n",
        "# print(pd.unique(train['Sex']))\n",
        "# > ['male' 'female']\n",
        "\n",
        "# drop_col_list = ['Name','Ticket','Fare','Cabin','Embarked']\n",
        "# train.drop(drop_col_list,axis='columns',inplace=True)\n",
        "\n",
        "\n",
        "def pre_processing(df):\n",
        "    # 欠損値に設定するデータはtrainで固定するべきでは？参考サイトではtestもtestで中央値を計算しているが\n",
        "    age_na_fill = df['Age'].median()\n",
        "    fare_na_fill = df['Fare'].median()\n",
        "\n",
        "    df['Age'] = df['Age'].fillna(age_na_fill)\n",
        "    df['Embarked'] = df['Embarked'].fillna(embarked_na_fill)\n",
        "    df['Fare'] = df['Fare'].fillna(fare_na_fill)\n",
        "    # df['Sex'][df['Sex']=='male'] = 0\n",
        "    # df['Sex'][df['Sex']=='female'] = 1\n",
        "    # df['Embarked'][df['Embarked']=='S'] = 0\n",
        "    # df['Embarked'][df['Embarked']=='C'] = 1\n",
        "    # df['Embarked'][df['Embarked']=='Q'] = 2\n",
        "    df['Sex'].replace({'male':0,'female':1},inplace=True)\n",
        "    df['Embarked'].replace({'S':0,'C':1,'Q':2},inplace=True)\n",
        "\n",
        "    return(df)\n",
        "\n",
        "print(kesson_table(train))\n",
        "\n",
        "print(train.head(10))\n",
        "\n",
        "train = pre_processing(train)\n",
        "test = pre_processing(test)\n",
        "\n",
        "print(train.head(10))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             欠損数          %\n",
            "PassengerId    0   0.000000\n",
            "Survived       0   0.000000\n",
            "Pclass         0   0.000000\n",
            "Name           0   0.000000\n",
            "Sex            0   0.000000\n",
            "Age          177  19.865320\n",
            "SibSp          0   0.000000\n",
            "Parch          0   0.000000\n",
            "Ticket         0   0.000000\n",
            "Fare           0   0.000000\n",
            "Cabin        687  77.104377\n",
            "Embarked       2   0.224467\n",
            "   PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
            "0            1         0       3  ...   7.2500   NaN         S\n",
            "1            2         1       1  ...  71.2833   C85         C\n",
            "2            3         1       3  ...   7.9250   NaN         S\n",
            "3            4         1       1  ...  53.1000  C123         S\n",
            "4            5         0       3  ...   8.0500   NaN         S\n",
            "5            6         0       3  ...   8.4583   NaN         Q\n",
            "6            7         0       1  ...  51.8625   E46         S\n",
            "7            8         0       3  ...  21.0750   NaN         S\n",
            "8            9         1       3  ...  11.1333   NaN         S\n",
            "9           10         1       2  ...  30.0708   NaN         C\n",
            "\n",
            "[10 rows x 12 columns]\n",
            "   PassengerId  Survived  Pclass  ...     Fare  Cabin  Embarked\n",
            "0            1         0       3  ...   7.2500    NaN         0\n",
            "1            2         1       1  ...  71.2833    C85         1\n",
            "2            3         1       3  ...   7.9250    NaN         0\n",
            "3            4         1       1  ...  53.1000   C123         0\n",
            "4            5         0       3  ...   8.0500    NaN         0\n",
            "5            6         0       3  ...   8.4583    NaN         2\n",
            "6            7         0       1  ...  51.8625    E46         0\n",
            "7            8         0       3  ...  21.0750    NaN         0\n",
            "8            9         1       3  ...  11.1333    NaN         0\n",
            "9           10         1       2  ...  30.0708    NaN         1\n",
            "\n",
            "[10 rows x 12 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2yFKUwf-NmX"
      },
      "source": [
        "### 決定木"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-15T16:43:10.269071Z",
          "iopub.execute_input": "2021-10-15T16:43:10.269556Z",
          "iopub.status.idle": "2021-10-15T16:43:11.961466Z",
          "shell.execute_reply.started": "2021-10-15T16:43:10.269481Z",
          "shell.execute_reply": "2021-10-15T16:43:11.960585Z"
        },
        "trusted": true,
        "id": "0gukoulb-NmY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f403d9a1-fbf0-4a2a-c7f1-91fb22de6486"
      },
      "source": [
        "from IPython.display import FileLink\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "exp_vals = ['Pclass','Sex','Age','Fare']\n",
        "\n",
        "target = train['Survived'].values\n",
        "features_one = train[exp_vals].values\n",
        "print(features_one[:10])\n",
        "\n",
        "# 決定木の作成\n",
        "my_tree_one = tree.DecisionTreeClassifier()\n",
        "my_tree_one = my_tree_one.fit(features_one,target)\n",
        "\n",
        "train_pred_y = my_tree_one.predict(features_one)\n",
        "score = f1_score(target, train_pred_y, average=\"micro\")\n",
        "print('f1　score: ',score)\n",
        "\n",
        "    \n",
        "# testの説明変数の値を取得\n",
        "test_features = test[exp_vals].values\n",
        "\n",
        "# testの説明変数を使ってmy_tree_oneのモデルで予測\n",
        "my_prediction = my_tree_one.predict(test_features)\n",
        "\n",
        "print(my_prediction.shape)\n",
        "print(my_prediction[:10])\n",
        "\n",
        "def export_predict(my_prediction,fname):\n",
        "    # PassengerIdを取得\n",
        "    PassengerId = np.array(test['PassengerId']).astype(int)\n",
        "    # my_predistionとPassengerIdをデータフレームに落とし込む\n",
        "    my_solution = pd.DataFrame(my_prediction,PassengerId,columns=['Survived'])\n",
        "    # my_tree_one.csvとして書き出し\n",
        "    my_solution.to_csv(fname,index_label=['PassengerId'])\n",
        "    FileLink(fname)\n",
        "    print(my_solution.head(3))\n",
        "\n",
        "export_predict(my_prediction,'my_tree_one.csv')\n",
        "\n",
        "# !zip -r file.zip 'my_tree_one.csv' \n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3.      0.     22.      7.25  ]\n",
            " [ 1.      1.     38.     71.2833]\n",
            " [ 3.      1.     26.      7.925 ]\n",
            " [ 1.      1.     35.     53.1   ]\n",
            " [ 3.      0.     35.      8.05  ]\n",
            " [ 3.      0.     28.      8.4583]\n",
            " [ 1.      0.     54.     51.8625]\n",
            " [ 3.      0.      2.     21.075 ]\n",
            " [ 3.      1.     27.     11.1333]\n",
            " [ 2.      1.     14.     30.0708]]\n",
            "f1　score:  0.9775533108866442\n",
            "(418,)\n",
            "[0 0 1 1 1 0 0 0 1 0]\n",
            "     Survived\n",
            "892         0\n",
            "893         0\n",
            "894         1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnjgmyIc-NmZ"
      },
      "source": [
        "### 決定木＋7つの説明変数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-15T16:43:11.962802Z",
          "iopub.execute_input": "2021-10-15T16:43:11.963077Z",
          "iopub.status.idle": "2021-10-15T16:43:11.989126Z",
          "shell.execute_reply.started": "2021-10-15T16:43:11.963051Z",
          "shell.execute_reply": "2021-10-15T16:43:11.987744Z"
        },
        "trusted": true,
        "id": "cESR4c0W-NmZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b52f8bc-f369-4eaa-9db0-d1cabd7b21ed"
      },
      "source": [
        "\n",
        "\n",
        "def dec_tree(train,test,exp_vals,target_col):\n",
        "\n",
        "    target = train[target_col].values\n",
        "    features = train[exp_vals].values\n",
        "    print(features[:3])\n",
        "\n",
        "    # 決定木の作成とArgumentの設定\n",
        "    max_depth = 10\n",
        "    min_samples_split = 5\n",
        "    my_dec_tree = tree.DecisionTreeClassifier(max_depth=max_depth\n",
        "                                                ,min_samples_split=min_samples_split\n",
        "                                                ,random_state=1)\n",
        "    my_dec_tree = my_dec_tree.fit(features,target)\n",
        "    train_pred_y = my_dec_tree.predict(features)\n",
        "\n",
        "    # print(f\"acc: {my_dec_tree.score(train, target_col)}\")\n",
        "    # acc: 0.9416666666666667\n",
        "    \n",
        "    score = f1_score(target, train_pred_y, average=\"micro\")\n",
        "    print('f1　score: ',score)\n",
        "\n",
        "\n",
        "    # testの説明変数の値を取得\n",
        "    test_features = test[exp_vals].values\n",
        "\n",
        "    # testの説明変数を使ってmy_tree_oneのモデルで予測\n",
        "    my_pred_tree = my_dec_tree.predict(test_features)\n",
        "\n",
        "    return(my_pred_tree)\n",
        "\n",
        "\n",
        "exp_vals = ['Pclass','Sex','Age','Fare', 'SibSp','Parch','Embarked']\n",
        "\n",
        "my_prediction_tree_two = dec_tree(train,test,exp_vals,'Survived')\n",
        "\n",
        "export_predict(my_prediction_tree_two,'my_tree_two.csv')\n",
        "\n",
        "print(my_prediction_tree_two.shape)\n",
        "print(my_prediction_tree_two[:10])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3.      0.     22.      7.25    1.      0.      0.    ]\n",
            " [ 1.      1.     38.     71.2833  1.      0.      1.    ]\n",
            " [ 3.      1.     26.      7.925   0.      0.      0.    ]]\n",
            "f1　score:  0.9057239057239057\n",
            "     Survived\n",
            "892         0\n",
            "893         0\n",
            "894         0\n",
            "(418,)\n",
            "[0 0 0 0 1 0 0 0 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ldld5RPM-Nma"
      },
      "source": [
        "## OneHotEncoding\n",
        "\n",
        "https://www.haya-programming.com/entry/2019/08/17/184527\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-15T16:43:11.990456Z",
          "iopub.execute_input": "2021-10-15T16:43:11.990785Z",
          "iopub.status.idle": "2021-10-15T16:43:12.072543Z",
          "shell.execute_reply.started": "2021-10-15T16:43:11.990755Z",
          "shell.execute_reply": "2021-10-15T16:43:12.071596Z"
        },
        "trusted": true,
        "id": "lKyBMD6O-Nmb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84537c48-0cf3-4c3d-cf84-2a29c085d415"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Data読み取り～欠損値補完\n",
        "def read_data():\n",
        "    train = pd.read_csv(data_path + 'train.csv')\n",
        "    test = pd.read_csv(data_path + 'test.csv')\n",
        "\n",
        "    embarked_na_fill = statistics.mode(train['Embarked'])\n",
        "    # 欠損値に設定するデータはtrainで固定するべきでは？参考サイトではtestもtestで中央値を計算しているが\n",
        "    age_na_fill = train['Age'].median()\n",
        "    fare_na_fill = train['Fare'].median()\n",
        "\n",
        "    train['Age'] = train['Age'].fillna(age_na_fill)\n",
        "    train['Embarked'] = train['Embarked'].fillna(embarked_na_fill)\n",
        "    train['Fare'] = train['Fare'].fillna(fare_na_fill)\n",
        "\n",
        "    test['Age'] = test['Age'].fillna(age_na_fill)\n",
        "    test['Embarked'] = test['Embarked'].fillna(embarked_na_fill)\n",
        "    test['Fare'] = test['Fare'].fillna(fare_na_fill)\n",
        "    return train,test\n",
        "\n",
        "# 各列のカテゴリ数チェック\n",
        "for col in train.columns:\n",
        "    print(col,len(pd.unique(train[col])))\n",
        "\n",
        "train,test = read_data()\n",
        "\n",
        "# train2 = train.drop(['PassengerId','Survived','Name','Ticket','Cabin'],axis='columns')\n",
        "# test2 = test.drop(['PassengerId','Survived','Name','Ticket','Cabin'],axis='columns')\n",
        "\n",
        "to_ohe_col = ['Sex','Embarked']\n",
        "# to_ohe_col = ['Pclass','Sex','Embarked']\n",
        "\n",
        "\n",
        "def change_ohe(df,col):\n",
        "    ohe = OneHotEncoder(handle_unknown='ignore',sparse=False,dtype=np.float32)\n",
        "    ohe.fit(pd.DataFrame(df[cols]))\n",
        "    print(col,ohe.categories_,len(ohe.categories_))\n",
        "    ohe_array = ohe.transform(pd.DataFrame(df[col]))\n",
        "    print(ohe_array)\n",
        "    df_new = df.drop(col,axis='columns').join(pd.DataFrame(ohe_array,columns=ohe.categories_[0]))\n",
        "    print(df_new)\n",
        "\n",
        "# ohe fit\n",
        "def ohe_fit(df,cols):\n",
        "    ohe = OneHotEncoder(handle_unknown='ignore',sparse=False,dtype=np.float32)\n",
        "    ohe.fit(pd.DataFrame(df[cols]))\n",
        "    return(ohe)\n",
        "\n",
        "# ohe trasform\n",
        "def ohe_transform(df,cols,ohe):\n",
        "    ohe_array = ohe.transform(pd.DataFrame(df[cols]))\n",
        "    print(ohe_array)\n",
        "    return(df.join(pd.DataFrame(ohe_array,columns=np.concatenate(ohe.categories_))))\n",
        "\n",
        "ohe = ohe_fit(train,to_ohe_col)\n",
        "train2 = ohe_transform(train,to_ohe_col,ohe)\n",
        "test2 = ohe_transform(test,to_ohe_col,ohe)\n",
        "\n",
        "print(train2)\n",
        "print(test2)\n",
        "# train6 = change_ohe(train2,'Embarked')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PassengerId 891\n",
            "Survived 2\n",
            "Pclass 3\n",
            "Name 891\n",
            "Sex 2\n",
            "Age 88\n",
            "SibSp 7\n",
            "Parch 7\n",
            "Ticket 681\n",
            "Fare 248\n",
            "Cabin 148\n",
            "Embarked 3\n",
            "[[0. 1. 0. 0. 1.]\n",
            " [1. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 1.]\n",
            " ...\n",
            " [1. 0. 0. 0. 1.]\n",
            " [0. 1. 1. 0. 0.]\n",
            " [0. 1. 0. 1. 0.]]\n",
            "[[0. 1. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 1. 0.]\n",
            " ...\n",
            " [0. 1. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 1.]\n",
            " [0. 1. 1. 0. 0.]]\n",
            "     PassengerId  Survived  Pclass  ...    C    Q    S\n",
            "0              1         0       3  ...  0.0  0.0  1.0\n",
            "1              2         1       1  ...  1.0  0.0  0.0\n",
            "2              3         1       3  ...  0.0  0.0  1.0\n",
            "3              4         1       1  ...  0.0  0.0  1.0\n",
            "4              5         0       3  ...  0.0  0.0  1.0\n",
            "..           ...       ...     ...  ...  ...  ...  ...\n",
            "886          887         0       2  ...  0.0  0.0  1.0\n",
            "887          888         1       1  ...  0.0  0.0  1.0\n",
            "888          889         0       3  ...  0.0  0.0  1.0\n",
            "889          890         1       1  ...  1.0  0.0  0.0\n",
            "890          891         0       3  ...  0.0  1.0  0.0\n",
            "\n",
            "[891 rows x 17 columns]\n",
            "     PassengerId  Pclass  ...    Q    S\n",
            "0            892       3  ...  1.0  0.0\n",
            "1            893       3  ...  0.0  1.0\n",
            "2            894       2  ...  1.0  0.0\n",
            "3            895       3  ...  0.0  1.0\n",
            "4            896       3  ...  0.0  1.0\n",
            "..           ...     ...  ...  ...  ...\n",
            "413         1305       3  ...  0.0  1.0\n",
            "414         1306       1  ...  0.0  0.0\n",
            "415         1307       3  ...  0.0  1.0\n",
            "416         1308       3  ...  0.0  1.0\n",
            "417         1309       3  ...  0.0  0.0\n",
            "\n",
            "[418 rows x 16 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfOk0tgLCsap"
      },
      "source": [
        "### 決定木のスコア"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-15T16:43:12.074138Z",
          "iopub.execute_input": "2021-10-15T16:43:12.074443Z",
          "iopub.status.idle": "2021-10-15T16:43:12.869003Z",
          "shell.execute_reply.started": "2021-10-15T16:43:12.074414Z",
          "shell.execute_reply": "2021-10-15T16:43:12.867835Z"
        },
        "trusted": true,
        "id": "f7whXdAY-Nmc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa827d67-97b0-402c-ae60-b3518d374600"
      },
      "source": [
        "exp_vals = ['Pclass','Age','Fare','SibSp','Parch','female','male','C','Q','S']\n",
        "\n",
        "my_prediction_tree_3rd = dec_tree(train2,test2,exp_vals,'Survived')\n",
        "\n",
        "export_predict(my_prediction_tree_two,'my_tree_3rd.csv')\n",
        "\n",
        "print(my_prediction_tree_two.shape)\n",
        "print(my_prediction_tree_two[:10])\n",
        "\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3.     22.      7.25    1.      0.      0.      1.      0.      0.\n",
            "   1.    ]\n",
            " [ 1.     38.     71.2833  1.      0.      1.      0.      1.      0.\n",
            "   0.    ]\n",
            " [ 3.     26.      7.925   0.      0.      1.      0.      0.      0.\n",
            "   1.    ]]\n",
            "f1　score:  0.9124579124579124\n",
            "     Survived\n",
            "892         0\n",
            "893         0\n",
            "894         0\n",
            "(418,)\n",
            "[0 0 0 0 1 0 0 0 1 0]\n",
            "gender_submission.csv  my_tree_one.csv\tsample_data  titanic.zip\n",
            "my_tree_3rd.csv        my_tree_two.csv\ttest.csv     train.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvU_vKx4-Nmb"
      },
      "source": [
        "## RandomForest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-15T16:43:16.883085Z",
          "iopub.execute_input": "2021-10-15T16:43:16.883485Z",
          "iopub.status.idle": "2021-10-15T16:43:17.616282Z",
          "shell.execute_reply.started": "2021-10-15T16:43:16.883451Z",
          "shell.execute_reply": "2021-10-15T16:43:17.615438Z"
        },
        "trusted": true,
        "id": "krbbf__E-Nmc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1fba751-7c47-4d93-9f75-17ed6f4bd379"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "train_labels = ['Pclass','Age','Fare','SibSp','Parch','female','male','C','Q','S']\n",
        "\n",
        "def rand_tree(train,test,train_labels,target_col):\n",
        "\n",
        "    target = train[target_col].values\n",
        "    features = train[train_labels].values\n",
        "    print(features[:3])\n",
        "\n",
        "    clf = RandomForestClassifier(verbose=True,   # 学習中にログを表示\n",
        "                              n_jobs=-1,         # 複数のCPUコアを使って並列に学習します。-1は最大値。\n",
        "                              random_state=2525) # 乱数シード\n",
        "    clf.fit(features, target)\n",
        "    train_pred_y = clf.predict(features)\n",
        "\n",
        "    # print(f\"acc: {my_dec_tree.score(train, target_col)}\")\n",
        "    # acc: 0.9416666666666667\n",
        "    \n",
        "    score = f1_score(target, train_pred_y, average=\"micro\")\n",
        "    print('f1　score: ',score)\n",
        "\n",
        "    print('feature_importances: ',clf.feature_importances_)\n",
        "\n",
        "    # testの説明変数の値を取得\n",
        "    test_features = test[exp_vals].values\n",
        "\n",
        "    # testの説明変数を使ってmy_tree_oneのモデルで予測\n",
        "    pred = clf.predict(test_features)\n",
        "\n",
        "    return(pred)\n",
        "\n",
        "pred = rand_tree(train2,test2,train_labels,'Survived')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3.     22.      7.25    1.      0.      0.      1.      0.      0.\n",
            "   1.    ]\n",
            " [ 1.     38.     71.2833  1.      0.      1.      0.      1.      0.\n",
            "   0.    ]\n",
            " [ 3.     26.      7.925   0.      0.      1.      0.      0.      0.\n",
            "   1.    ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1　score:  0.9797979797979798\n",
            "feature_importances:  [0.08916066 0.25136058 0.25018454 0.04797674 0.03797231 0.15155346\n",
            " 0.13835768 0.01250642 0.00717972 0.01374788]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hH6stmi-Nmc"
      },
      "source": [
        "## Grid Search\n",
        "Kaggle(42) - タイタニックをRandom Forestで予測 - グリッドサーチでパラメータの最適化 - PythonとRPAで遊ぶ\n",
        "https://ailog.site/2021/03/20/2021/0320/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-15T16:54:42.717474Z",
          "iopub.execute_input": "2021-10-15T16:54:42.717953Z",
          "iopub.status.idle": "2021-10-15T17:02:49.332142Z",
          "shell.execute_reply.started": "2021-10-15T16:54:42.717908Z",
          "shell.execute_reply": "2021-10-15T17:02:49.33133Z"
        },
        "trusted": true,
        "id": "AEJ2w72Y-Nmc"
      },
      "source": [
        "from sklearn import ensemble, model_selection\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# 試行するパラメータを羅列\n",
        "params = {\n",
        "    'criterion'   : ['gini', 'entropy'],\n",
        "    'n_estimators': [10, 100, 300, 500, 1000, 1500, 2000],\n",
        "    'max_depth'   : [3, 5, 7, 9, 11]\n",
        "}\n",
        "train_x = train2[train_labels].values\n",
        "train_y = train2['Survived'].values\n",
        "\n",
        "clf = ensemble.RandomForestClassifier()\n",
        "\n",
        "grid_search = GridSearchCV(clf, param_grid=params, cv=4)\n",
        "\n",
        "## 6分くらいかかる\n",
        "# %time grid_search.fit(train_x, train_y)\n",
        "# print(grid_search.best_score_)\n",
        "# print(grid_search.best_params_)\n",
        "\n",
        "# CPU times: user 6min 38s, sys: 3.32 s, total: 6min 41s\n",
        "# Wall time: 6min 40s\n",
        "# 0.8372722498283036\n",
        "# {'criterion': 'entropy', 'max_depth': 9, 'n_estimators': 300}\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yElD5_z0-Nmd"
      },
      "source": [
        "## PipeLine\n",
        "\n",
        "ColumnTransformerで特徴ごとに異なる変換を行うパイプラインを構築する | DevelopersIO  \n",
        "https://dev.classmethod.jp/articles/how_to_use_columntransformer_sklearn/\n",
        "\n",
        "scikit-learnのpipelineモジュールで機械学習パイプラインを作る | DevelopersIO  \n",
        "https://dev.classmethod.jp/articles/create_pipeline_scikit-learn_pipeline/\n",
        "\n",
        "Python: scikit-learn の Pipeline を使ってみる - CUBE SUGAR CONTAINER  \n",
        "https://blog.amedama.jp/entry/2018/07/07/223257"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-14T14:13:56.865787Z",
          "iopub.status.idle": "2021-10-14T14:13:56.866552Z"
        },
        "trusted": true,
        "id": "n_kgN4Q2-Nmd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "outputId": "285a6b0c-0c48-48c2-ed6f-6b6b5b09c30a"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import set_config\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# from sklearn.experimental import enable_hist_gradient_boosting\n",
        "# from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "\n",
        "# Pipeline\n",
        "# \n",
        "\n",
        "df_train = pd.read_csv(data_path + 'train.csv')\n",
        "df_target = pd.read_csv(data_path + 'test.csv')\n",
        "\n",
        "# カラムの型を確認\n",
        "print(df_train)\n",
        "\n",
        "# <class 'pandas.core.frame.DataFrame'>\n",
        "# RangeIndex: 891 entries, 0 to 890\n",
        "# Data columns (total 12 columns):\n",
        "#  #   Column       Non-Null Count  Dtype  \n",
        "# ---  ------       --------------  -----  \n",
        "#  0   PassengerId  891 non-null    int64  \n",
        "#  1   Survived     891 non-null    int64  \n",
        "#  2   Pclass       891 non-null    int64  \n",
        "#  3   Name         891 non-null    object \n",
        "#  4   Sex          891 non-null    object \n",
        "#  5   Age          714 non-null    float64\n",
        "#  6   SibSp        891 non-null    int64  \n",
        "#  7   Parch        891 non-null    int64  \n",
        "#  8   Ticket       891 non-null    object \n",
        "#  9   Fare         891 non-null    float64\n",
        "#  10  Cabin        204 non-null    object \n",
        "#  11  Embarked     889 non-null    object \n",
        "# dtypes: float64(2), int64(5), object(5)\n",
        "# memory usage: 83.7+ KB\n",
        "\n",
        "## 欠損値の確認\n",
        "# print(df_train.isnull().sum())\n",
        "\n",
        "## 特徴と推定対象に分離\n",
        "X = df_train.drop(['PassengerId','Name','Ticket','Fare','Cabin'], axis=1)\n",
        "y = df_train['Survived']\n",
        "\n",
        "X_target = df_target.drop(['PassengerId','Name','Ticket','Fare','Cabin'], axis=1)\n",
        "\n",
        "## 欠損値の確認\n",
        "print(X.isnull().sum()[X.isnull().sum() > 0])\n",
        "# Age         177\n",
        "# Embarked      2\n",
        "print(X_target.isnull().sum()[X_target.isnull().sum() > 0])\n",
        "# Age    86\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "# 量的変数の前処理\n",
        "# numeric_features = [\"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\", \"body_mass_g\"]\n",
        "\n",
        "# numeric_transformer = Pipeline(steps=[\n",
        "#     ('num_imputer', SimpleImputer(strategy='median')),\n",
        "#     ('scaler', StandardScaler())])\n",
        "\n",
        "# カテゴリー変数の前処理1\n",
        "# Embarked：最頻値で欠損補完/ohe\n",
        "categorical_transformer1 = Pipeline(steps=[\n",
        "    ('cat_imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot1', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "# 前処理2\n",
        "# Sez：One-hotエンコーディング\n",
        "categorical_transformer2 = Pipeline(steps=[\n",
        "    ('onehot2', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "# 前処理3\n",
        "# Age：欠損値補完/One-hotエンコーディング\n",
        "categorical_transformer3 = Pipeline(steps=[\n",
        "    ('cat_imputer3', SimpleImputer(strategy='mean')),\n",
        "    ('onehot3', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "# ColumnTransformerの作成\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        # ('num', numeric_transformer, numeric_features),\n",
        "        ('cat1', categorical_transformer1, ['Embarked']),\n",
        "        ('cat2', categorical_transformer2, ['Sex']),\n",
        "        ('cat3', categorical_transformer3, ['Age'])])\n",
        "\n",
        "# 全体のパイプラインの作成\n",
        "pipe = Pipeline([(\"preprocessor\", preprocessor),  \n",
        "                 (\"RF\", RandomForestClassifier())]\n",
        "                #  (\"Classifier\", HistGradientBoostingClassifier())]\n",
        "                )\n",
        "\n",
        "set_config(display='diagram')   \n",
        "pipe\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
            "0              1         0       3  ...   7.2500   NaN         S\n",
            "1              2         1       1  ...  71.2833   C85         C\n",
            "2              3         1       3  ...   7.9250   NaN         S\n",
            "3              4         1       1  ...  53.1000  C123         S\n",
            "4              5         0       3  ...   8.0500   NaN         S\n",
            "..           ...       ...     ...  ...      ...   ...       ...\n",
            "886          887         0       2  ...  13.0000   NaN         S\n",
            "887          888         1       1  ...  30.0000   B42         S\n",
            "888          889         0       3  ...  23.4500   NaN         S\n",
            "889          890         1       1  ...  30.0000  C148         C\n",
            "890          891         0       3  ...   7.7500   NaN         Q\n",
            "\n",
            "[891 rows x 12 columns]\n",
            "Age         177\n",
            "Embarked      2\n",
            "dtype: int64\n",
            "Age    86\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style>#sk-dd06d977-4a29-4d7e-a646-289b3338550c {color: black;background-color: white;}#sk-dd06d977-4a29-4d7e-a646-289b3338550c pre{padding: 0;}#sk-dd06d977-4a29-4d7e-a646-289b3338550c div.sk-toggleable {background-color: white;}#sk-dd06d977-4a29-4d7e-a646-289b3338550c label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-dd06d977-4a29-4d7e-a646-289b3338550c div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-dd06d977-4a29-4d7e-a646-289b3338550c div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-dd06d977-4a29-4d7e-a646-289b3338550c input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-dd06d977-4a29-4d7e-a646-289b3338550c div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-dd06d977-4a29-4d7e-a646-289b3338550c div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-dd06d977-4a29-4d7e-a646-289b3338550c input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-dd06d977-4a29-4d7e-a646-289b3338550c div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-dd06d977-4a29-4d7e-a646-289b3338550c div.sk-estimator:hover {background-color: #d4ebff;}#sk-dd06d977-4a29-4d7e-a646-289b3338550c div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-dd06d977-4a29-4d7e-a646-289b3338550c div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-dd06d977-4a29-4d7e-a646-289b3338550c div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-dd06d977-4a29-4d7e-a646-289b3338550c div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-dd06d977-4a29-4d7e-a646-289b3338550c div.sk-item {z-index: 1;}#sk-dd06d977-4a29-4d7e-a646-289b3338550c div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-dd06d977-4a29-4d7e-a646-289b3338550c div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-dd06d977-4a29-4d7e-a646-289b3338550c div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-dd06d977-4a29-4d7e-a646-289b3338550c div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-dd06d977-4a29-4d7e-a646-289b3338550c div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-dd06d977-4a29-4d7e-a646-289b3338550c div.sk-parallel-item:only-child::after {width: 0;}#sk-dd06d977-4a29-4d7e-a646-289b3338550c div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-dd06d977-4a29-4d7e-a646-289b3338550c div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-dd06d977-4a29-4d7e-a646-289b3338550c div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-dd06d977-4a29-4d7e-a646-289b3338550c div.sk-container {display: inline-block;position: relative;}</style><div id=\"sk-dd06d977-4a29-4d7e-a646-289b3338550c\" class\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"66560f46-6e4e-4491-9cca-c161953e59f7\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"66560f46-6e4e-4491-9cca-c161953e59f7\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[('preprocessor',\n",
              "                 ColumnTransformer(transformers=[('cat1',\n",
              "                                                  Pipeline(steps=[('cat_imputer',\n",
              "                                                                   SimpleImputer(strategy='most_frequent')),\n",
              "                                                                  ('onehot1',\n",
              "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
              "                                                  ['Embarked']),\n",
              "                                                 ('cat2',\n",
              "                                                  Pipeline(steps=[('onehot2',\n",
              "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
              "                                                  ['Sex']),\n",
              "                                                 ('cat3',\n",
              "                                                  Pipeline(steps=[('cat_imputer3',\n",
              "                                                                   SimpleImputer()),\n",
              "                                                                  ('onehot3',\n",
              "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
              "                                                  ['Age'])])),\n",
              "                ('RF', RandomForestClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"66f3db04-9c79-4817-ba38-8b9dd7c823b9\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"66f3db04-9c79-4817-ba38-8b9dd7c823b9\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[('cat1',\n",
              "                                 Pipeline(steps=[('cat_imputer',\n",
              "                                                  SimpleImputer(strategy='most_frequent')),\n",
              "                                                 ('onehot1',\n",
              "                                                  OneHotEncoder(handle_unknown='ignore'))]),\n",
              "                                 ['Embarked']),\n",
              "                                ('cat2',\n",
              "                                 Pipeline(steps=[('onehot2',\n",
              "                                                  OneHotEncoder(handle_unknown='ignore'))]),\n",
              "                                 ['Sex']),\n",
              "                                ('cat3',\n",
              "                                 Pipeline(steps=[('cat_imputer3',\n",
              "                                                  SimpleImputer()),\n",
              "                                                 ('onehot3',\n",
              "                                                  OneHotEncoder(handle_unknown='ignore'))]),\n",
              "                                 ['Age'])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"2c1e8af9-7554-4125-997c-073240c6a286\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"2c1e8af9-7554-4125-997c-073240c6a286\">cat1</label><div class=\"sk-toggleable__content\"><pre>['Embarked']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"79a2ce70-3dd7-43e5-a854-5972e79afac0\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"79a2ce70-3dd7-43e5-a854-5972e79afac0\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy='most_frequent')</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"cc4989ee-7daa-42f0-9d39-2235142932ff\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"cc4989ee-7daa-42f0-9d39-2235142932ff\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown='ignore')</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"5cf7bc49-15fb-4994-a1f7-eb74503a3517\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"5cf7bc49-15fb-4994-a1f7-eb74503a3517\">cat2</label><div class=\"sk-toggleable__content\"><pre>['Sex']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"21629503-3770-4d2d-9460-b879cdb3bd79\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"21629503-3770-4d2d-9460-b879cdb3bd79\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown='ignore')</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"9ca89e9f-1e26-4759-83d5-9c3c96cc199d\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"9ca89e9f-1e26-4759-83d5-9c3c96cc199d\">cat3</label><div class=\"sk-toggleable__content\"><pre>['Age']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"e2829bbd-9b1d-4e88-91c8-baeeef3f015c\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"e2829bbd-9b1d-4e88-91c8-baeeef3f015c\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"eaaf8e27-063e-427d-b3cf-480a1fe7eb0d\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"eaaf8e27-063e-427d-b3cf-480a1fe7eb0d\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown='ignore')</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"04c55705-5d5a-4bdd-9464-f2424a28d5ff\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"04c55705-5d5a-4bdd-9464-f2424a28d5ff\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('preprocessor',\n",
              "                 ColumnTransformer(transformers=[('cat1',\n",
              "                                                  Pipeline(steps=[('cat_imputer',\n",
              "                                                                   SimpleImputer(strategy='most_frequent')),\n",
              "                                                                  ('onehot1',\n",
              "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
              "                                                  ['Embarked']),\n",
              "                                                 ('cat2',\n",
              "                                                  Pipeline(steps=[('onehot2',\n",
              "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
              "                                                  ['Sex']),\n",
              "                                                 ('cat3',\n",
              "                                                  Pipeline(steps=[('cat_imputer3',\n",
              "                                                                   SimpleImputer()),\n",
              "                                                                  ('onehot3',\n",
              "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
              "                                                  ['Age'])])),\n",
              "                ('RF', RandomForestClassifier())])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idzs4yWtDRgr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83e508a7-6dea-4ff7-940f-cb4b149e2f3e"
      },
      "source": [
        "## 訓練データで性能を確認\n",
        "pipe.fit(X_train, y_train)\n",
        "y_pred = pipe.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "print('f1 score: ',f1_score(target, train_pred_y, average=\"micro\"))\n",
        "print('accuracy: ',accuracy_score(y_test, y_pred))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1 score:  0.9775533108866442\n",
            "accuracy:  0.7443946188340808\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7BQhpfdKMgH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a8a3bf1-3ec0-444a-f16f-5f875af26b49"
      },
      "source": [
        "## 交差検証\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(pipe, \n",
        "                         X_train, \n",
        "                         y_train.values.ravel(), \n",
        "                         cv=5,\n",
        "                         scoring='accuracy')\n",
        "print(scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.73134328 0.80597015 0.73134328 0.76691729 0.80451128]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jsBXhoIC129"
      },
      "source": [
        "## 交差検証(cross_validate)\n",
        "\n",
        "cross_val_scoreはもうやめようね。一発で交差検証するにはcross_validateを使う - 静かなる名辞  \n",
        "https://www.haya-programming.com/entry/2018/03/31/184557  \n",
        "Python: scikit-learn の cross_validate() 関数で独自の評価指標を計算する - CUBE SUGAR CONTAINER  \n",
        "https://blog.amedama.jp/entry/sklearn-cv-custom-metric\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "aKUb0EEc-Nmd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b33c7dca-6775-4f2b-f880-491481bf2449"
      },
      "source": [
        "from pprint import pprint\n",
        "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
        "\n",
        "# モデルを用意する\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Stratified k-Fold で汎化性能を評価する\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "# 評価する指標\n",
        "score_funcs = [\n",
        "    'accuracy',\n",
        "    'precision',\n",
        "    'recall',\n",
        "    'f1',\n",
        "]\n",
        "# Cross Validation で検証する\n",
        "scores = cross_validate(clf, X, y, cv=skf, scoring=score_funcs)\n",
        "# 得られた指標を出力する\n",
        "print('accuracy:', scores['test_accuracy'].mean())\n",
        "print('precision:', scores['test_precision'].mean())\n",
        "print('recall:', scores['test_recall'].mean())\n",
        "print('f1:', scores['test_f1'].mean())\n",
        "\n",
        "\n",
        "gnb = GaussianNB()\n",
        "\n",
        "scoring = {\"p\": \"precision_macro\",\n",
        "            \"r\": \"recall_macro\",\n",
        "            \"f\":\"f1_macro\"}\n",
        "\n",
        "skf = StratifiedKFold(shuffle=True, random_state=0)\n",
        "scores = cross_validate(gnb, iris.data, iris.target,\n",
        "                        cv=skf, scoring=scoring)\n",
        "pprint(scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: nan\n",
            "precision: nan\n",
            "recall: nan\n",
            "f1: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "5 fits failed out of a total of 5.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "4 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\", line 328, in fit\n",
            "    X, y, multi_output=True, accept_sparse=\"csc\", dtype=DTYPE\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 576, in _validate_data\n",
            "    X, y = check_X_y(X, y, **check_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 968, in check_X_y\n",
            "    estimator=estimator,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 738, in check_array\n",
            "    array = np.asarray(array, order=order, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py\", line 83, in asarray\n",
            "    return array(a, dtype, copy=False, order=order)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\", line 1781, in __array__\n",
            "    return np.asarray(self._values, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py\", line 83, in asarray\n",
            "    return array(a, dtype, copy=False, order=order)\n",
            "ValueError: could not convert string to float: 'male'\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\", line 328, in fit\n",
            "    X, y, multi_output=True, accept_sparse=\"csc\", dtype=DTYPE\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 576, in _validate_data\n",
            "    X, y = check_X_y(X, y, **check_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 968, in check_X_y\n",
            "    estimator=estimator,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 738, in check_array\n",
            "    array = np.asarray(array, order=order, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py\", line 83, in asarray\n",
            "    return array(a, dtype, copy=False, order=order)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\", line 1781, in __array__\n",
            "    return np.asarray(self._values, dtype=dtype)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py\", line 83, in asarray\n",
            "    return array(a, dtype, copy=False, order=order)\n",
            "ValueError: could not convert string to float: 'female'\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-9941198dbc68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mgnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m scoring = {\"p\": \"precision_macro\",\n",
            "\u001b[0;31mNameError\u001b[0m: name 'GaussianNB' is not defined"
          ]
        }
      ]
    }
  ]
}